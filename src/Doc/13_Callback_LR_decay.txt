這個檔案包含13_Callback_LR_decay.py所有細節:


1. 第75 ~ 82行中:
=> ReduceLROnPlateau 回調函數，該回調函數會在模型訓練過程中動態調整學習率，以提高訓練效果。
=> monitor = 'val_accuracy'：
    監控的指標是驗證準確率。在訓練過程中，ReduceLROnPlateau 會觀察驗證準確率的變化。
=> factor = 0.5：
    當監控指標在給定的 patience 內沒有改善時，學習率會乘以這個衰減因子。這裡設置為 0.5，表示學習率會減半。
=> patience = 5：
    當監控指標（驗證準確率）在 5 個 epoch 內沒有提升時，學習率會被衰減。這個參數決定了在多少個 epoch 內指標沒有改善才會觸發學習率調整。
=> verbose = 1：
    設置為 1，表示在訓練過程中會輸出學習率調整的詳細信息。如果設置為 0，則不會輸出這些信息。
=> mode = 'max'：
    指定監控指標的模式。
    'max' 表示當驗證準確率不再提升時，觸發學習率調整。
    'min' 則表示當監控指標不再下降時觸發學習率調整。
=> min_lr = 0.0001：
    設置學習率的最小值。學習率不會被衰減到這個值以下，確保學習率不會降得太低，從而影響訓練效果。

2. Callback機制的意義?
在深度學習模型訓練中，Callback 是一種特殊的機制，用於在模型訓練過程中的特定時刻執行自定義代碼。

***補充:常見的 Callback 類型
1. ModelCheckpoint：
    用於在訓練過程中定期保存模型的權重，以便在訓練過程中出現中斷時能夠恢復訓練。

2. EarlyStopping：
    用於在模型的性能在驗證數據集上不再提升時提前停止訓練，以避免過擬合。

3. ReduceLROnPlateau：
    用於當監控指標（如驗證損失）在若干個 epoch 內不再改善時自動調整學習率。

4. TensorBoard：
    用於記錄訓練過程中的各種指標，並將這些數據可視化，以便使用 TensorBoard 工具進行分析。

5. 自定義 Callback：
    用戶可以根據需要自定義回調函數，以實現特殊的需求。自定義回調可以繼承 tf.keras.callbacks.Callback 類，並覆蓋其方法來定義自定義操作。